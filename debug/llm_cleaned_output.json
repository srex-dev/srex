{
      "slo": [
        {
          "name": "Availability SLO",
          "description": "Ensures that the service is available for a certain percentage of the time.",
          "sli": {
            "name": "Service Availability",
            "description": "The percentage of time the service is available.",
            "type": "Error Budget",
            "unit": "%",
            "source": "{{ service_name }}",
            "metric": "{error_budget:sum(rate({{ service_name }}_error[1m])) * 100}"
          },
          "target": {
            "value": 99.95,
            "time_window": "30d"
          }
        }
      ],
      "sli": [
        {
          "name": "Request Latency",
          "description": "The average time it takes to respond to a request.",
          "type": "Service Level Objective",
          "unit": "milliseconds",
          "source": "{{ service_name }}",
          "metric": "{histogram_quantile(0.5, sum(rate({{ service_name }}_request_duration_microseconds_bucket[1m]))}"
        },
        {
          "name": "Error Rate",
          "description": "The percentage of requests that result in an error.",
          "type": "Service Level Objective",
          "unit": "%",
          "source": "{{ service_name }}",
          "metric": "{error_budget:sum(rate({{ service_name }}_error[1m])) * 100}"
        }
      ],
      "alerts": [
        {
          "name": "High Request Latency Alert",
          "description": "Alerts when the average request latency exceeds 500 milliseconds.",
          "expr": "{histogram_quantile(0.5, sum(rate({{ service_name }}_request_duration_microseconds_bucket[1m]))} > 500",
          "for": "[30m]",
          "severity": "critical"
        },
        {
          "name": "High Error Rate Alert",
          "description": "Alerts when the error rate exceeds 2%.",
          "expr": "{error_budget:sum(rate({{ service_name }}_error[1m])) * 100} > 2",
          "for": "[5m]",
          "severity": "warning"
        }
      ],
      "explanation": "The SLOs are set to ensure a high level of availability and responsiveness for the service. The alerts notify when the service is not meeting these goals. Improvements can be made by optimizing code, reducing external dependencies, or implementing caching.",
      "llm_suggestions": [
        "Implement request tracing to better understand the flow of requests and identify bottlenecks",
        "Profile the service under load to identify areas for optimization"
      ]
    }